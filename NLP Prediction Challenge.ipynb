{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Prediction Challenge\n",
    "\n",
    "This notebook will walk through predicting which corpus a given sentence belongs to. We'll be using a BoW and a TF-IDF approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import spacy\n",
    "from nltk.corpus import pros_cons, stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package pros_cons to /Users/ryan/nltk_data...\n",
      "[nltk_data]   Package pros_cons is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# download the corpora that we want\n",
    "# and load the spacy english parser\n",
    "nltk.download('pros_cons')\n",
    "nlp = spacy.load('en')\n",
    "# set the max length to higher (we're dealing with a large corpus)\n",
    "nlp.max_length = 2000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['IntegratedCons.txt', 'IntegratedPros.txt']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pros_cons.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pro_sents = pros_cons.sents(\"IntegratedPros.txt\")\n",
    "con_sents = pros_cons.sents(\"IntegratedCons.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pros_doc = [\" \".join(sentence_tokens) for sentence_tokens in pro_sents]\n",
    "cons_doc = [\" \".join(sentence_tokens) for sentence_tokens in con_sents]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models\n",
    "\n",
    "Here we're going to use a few different models and see how high we can get our testing score. We'll then use the best trained model to perform k-fold cross validation to further investigate our testing accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set some parameters for grid search\n",
    "grid_search_params = {}\n",
    "\n",
    "# logistic regression possible parameters\n",
    "lr_params = {\"C\": [0.01, 0.1, 1., 10., 100.]}\n",
    "grid_search_params[LogisticRegression] = lr_params\n",
    "\n",
    "# random forrest possible parameters\n",
    "rf_params = {\n",
    "    \"n_estimators\": [10, 50, 100, 500],\n",
    "    \"criterion\": [\"gini\", \"entropy\"]\n",
    "}\n",
    "grid_search_params[RandomForestClassifier] = rf_params\n",
    "\n",
    "# ada-boost classifier\n",
    "ada_boost_params = {\n",
    "    \"n_estimators\": [10, 50, 100, 500],\n",
    "    \"learning_rate\": [0.01, 0.1, 1., 1.5, 2.0]\n",
    "}\n",
    "grid_search_params[AdaBoostClassifier] = ada_boost_params\n",
    "\n",
    "# gradient boosting classifier\n",
    "gbc_params = {\n",
    "    \"loss\": [\"deviance\", \"exponential\"],\n",
    "    \"learning_rate\": [0.01, 0.1, 1., 10],\n",
    "    \"n_estimators\": [5, 10, 50, 100, 500],\n",
    "    \"subsample\": [0.1, 0.3, 0.5, 0.8, 1.]\n",
    "}\n",
    "grid_search_params[GradientBoostingClassifier] = gbc_params\n",
    "\n",
    "# bernoulii naive bayes\n",
    "nb_params = {\n",
    "    \"alpha\": [0, 0.1, 1., 2., 10.]\n",
    "}\n",
    "grid_search_params[BernoulliNB] = nb_params\n",
    "\n",
    "# svc params\n",
    "svc_params = {\n",
    "    \"C\": [0.1, 1., 2., 10.],\n",
    "    \"gamma\": [\"auto\", \"scale\", 0.0001, 0.001, 0.01, 1., 10.]\n",
    "}\n",
    "grid_search_params[SVC] = svc_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_model(models, X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    # for each model, run grid search with the associated paramters\n",
    "    # and print the best train and test score, along with the best parameters\n",
    "    for model, params in models.items():\n",
    "        print(\"Training {}\".format(str(model.__name__)))\n",
    "        grid = GridSearchCV(model(), params, refit=True, verbose=0, iid=True, cv=20, n_jobs=4)\n",
    "        \n",
    "        grid.fit(X_train, y_train)\n",
    "        \n",
    "        print(\"Results for {}...\".format(str(model.__name__)))\n",
    "        print(\"---------------------\")\n",
    "        print(\"Best Score: {}\".format(grid.best_score_))\n",
    "        print(\"Train Score: {}\".format(grid.score(X_train, y_train)))\n",
    "        print(\"Test Score: {}\".format(grid.score(X_test, y_test)))\n",
    "        print(\"Best Params: {}\".format(grid.best_params_))\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF Approach\n",
    "This run will evaluate different models on the Tf-idf matrix using GridSearch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_td_idf_matrix(class1_corpus: list, class2_corpus: list):\n",
    "    \"\"\"Makes a TF-IDF matrix using the provided class corpora\n",
    "    and assigns the target_class to the matrix as well.\n",
    "    \n",
    "    Note: This would never work in production as the tf-idf score\n",
    "    requires knowledge of how many documents, etc. LSA makes sense,\n",
    "    but is not supervised, which is what we want.\n",
    "    \"\"\"\n",
    "    \n",
    "    # save the length of the first class\n",
    "    num_class1_sents = len(class1_corpus)\n",
    "    \n",
    "    # merge the two classes\n",
    "    all_sentences = class1_corpus + class2_corpus\n",
    "    \n",
    "    # compute the tf-idf matrix for all sentences\n",
    "    vectorizer = TfidfVectorizer(\n",
    "        max_df=0.5, # drop words that occur in more than half of the sentences\n",
    "        min_df=5, # only use words that appear at least 5 times overall\n",
    "        stop_words='english', # remove stop words, sampling from the english dictionary of stop words\n",
    "        lowercase=True, # prevent captitalization from ruining any potential matches\n",
    "        use_idf=True, # use the inverse document frequency in our weighting (duh)\n",
    "        norm=u'l2', # applies correction factor so that long and short sentences get \"treated equally\"\n",
    "        smooth_idf=True # adds 1 to all document frequencies (prevents devide by zero errors).\n",
    "    )\n",
    "    \n",
    "    # fit the matrix to the vectorizer\n",
    "    \n",
    "    td_idf_values = vectorizer.fit_transform(all_sentences)\n",
    "    \n",
    "    # create a pandas df from this data, using the feature names\n",
    "    df = pd.DataFrame(td_idf_values.todense(), columns=vectorizer.get_feature_names())\n",
    "    \n",
    "    # now assign the classes\n",
    "    df[\"CLASS_LABEL\"] = \"negative\"\n",
    "    # assign the positive class labels\n",
    "    df.at[:num_class1_sents, \"CLASS_LABEL\"] = \"positive\"\n",
    "    \n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized_data = make_td_idf_matrix(pros_doc, cons_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>1000</th>\n",
       "      <th>10x</th>\n",
       "      <th>11</th>\n",
       "      <th>11x17</th>\n",
       "      <th>12</th>\n",
       "      <th>120</th>\n",
       "      <th>...</th>\n",
       "      <th>young</th>\n",
       "      <th>yr</th>\n",
       "      <th>zeiss</th>\n",
       "      <th>zero</th>\n",
       "      <th>zone</th>\n",
       "      <th>zones</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zooming</th>\n",
       "      <th>zooms</th>\n",
       "      <th>CLASS_LABEL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.283573</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2961 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    00  000   10  100  1000  10x   11  11x17   12  120     ...       young  \\\n",
       "0  0.0  0.0  0.0  0.0   0.0  0.0  0.0    0.0  0.0  0.0     ...         0.0   \n",
       "1  0.0  0.0  0.0  0.0   0.0  0.0  0.0    0.0  0.0  0.0     ...         0.0   \n",
       "2  0.0  0.0  0.0  0.0   0.0  0.0  0.0    0.0  0.0  0.0     ...         0.0   \n",
       "3  0.0  0.0  0.0  0.0   0.0  0.0  0.0    0.0  0.0  0.0     ...         0.0   \n",
       "4  0.0  0.0  0.0  0.0   0.0  0.0  0.0    0.0  0.0  0.0     ...         0.0   \n",
       "\n",
       "    yr  zeiss  zero  zone  zones      zoom  zooming  zooms  CLASS_LABEL  \n",
       "0  0.0    0.0   0.0   0.0    0.0  0.000000      0.0    0.0     positive  \n",
       "1  0.0    0.0   0.0   0.0    0.0  0.000000      0.0    0.0     positive  \n",
       "2  0.0    0.0   0.0   0.0    0.0  0.283573      0.0    0.0     positive  \n",
       "3  0.0    0.0   0.0   0.0    0.0  0.000000      0.0    0.0     positive  \n",
       "4  0.0    0.0   0.0   0.0    0.0  0.000000      0.0    0.0     positive  \n",
       "\n",
       "[5 rows x 2961 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorized_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>1000</th>\n",
       "      <th>10x</th>\n",
       "      <th>11</th>\n",
       "      <th>11x17</th>\n",
       "      <th>12</th>\n",
       "      <th>120</th>\n",
       "      <th>...</th>\n",
       "      <th>young</th>\n",
       "      <th>yr</th>\n",
       "      <th>zeiss</th>\n",
       "      <th>zero</th>\n",
       "      <th>zone</th>\n",
       "      <th>zones</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zooming</th>\n",
       "      <th>zooms</th>\n",
       "      <th>CLASS_LABEL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45870</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45871</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45872</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45873</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45874</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2961 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        00  000   10  100  1000  10x   11  11x17   12  120     ...       \\\n",
       "45870  0.0  0.0  0.0  0.0   0.0  0.0  0.0    0.0  0.0  0.0     ...        \n",
       "45871  0.0  0.0  0.0  0.0   0.0  0.0  0.0    0.0  0.0  0.0     ...        \n",
       "45872  0.0  0.0  0.0  0.0   0.0  0.0  0.0    0.0  0.0  0.0     ...        \n",
       "45873  0.0  0.0  0.0  0.0   0.0  0.0  0.0    0.0  0.0  0.0     ...        \n",
       "45874  0.0  0.0  0.0  0.0   0.0  0.0  0.0    0.0  0.0  0.0     ...        \n",
       "\n",
       "       young   yr  zeiss  zero  zone  zones  zoom  zooming  zooms  CLASS_LABEL  \n",
       "45870    0.0  0.0    0.0   0.0   0.0    0.0   0.0      0.0    0.0     negative  \n",
       "45871    0.0  0.0    0.0   0.0   0.0    0.0   0.0      0.0    0.0     negative  \n",
       "45872    0.0  0.0    0.0   0.0   0.0    0.0   0.0      0.0    0.0     negative  \n",
       "45873    0.0  0.0    0.0   0.0   0.0    0.0   0.0      0.0    0.0     negative  \n",
       "45874    0.0  0.0    0.0   0.0   0.0    0.0   0.0      0.0    0.0     negative  \n",
       "\n",
       "[5 rows x 2961 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorized_data.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = vectorized_data.drop(columns=[\"CLASS_LABEL\"])\n",
    "target = vectorized_data[\"CLASS_LABEL\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_models = grid_search_params.copy()\n",
    "# remove some slow models fro the TF-IDF approach\n",
    "del tf_idf_models[AdaBoostClassifier]\n",
    "del tf_idf_models[GradientBoostingClassifier]\n",
    "del tf_idf_models[RandomForestClassifier]\n",
    "del tf_idf_models[SVC]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LogisticRegression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ryan/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for LogisticRegression...\n",
      "---------------------\n",
      "Best Score: 0.9066392625809666\n",
      "Train Score: 0.9342301943198804\n",
      "Test Score: 0.9075056310397442\n",
      "Best Params: {'C': 10.0}\n",
      "\n",
      "Training BernoulliNB\n",
      "Results for BernoulliNB...\n",
      "---------------------\n",
      "Best Score: 0.9044905331340309\n",
      "Train Score: 0.9150473343298455\n",
      "Test Score: 0.9066337281116036\n",
      "Best Params: {'alpha': 0.1}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "find_best_model(tf_idf_models, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our highest test score was with LogisticRegression, so let's cross validate with 20-fold CV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(C=10., solver=\"liblinear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='liblinear',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit to training data\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9075056310397442"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get test raw scores\n",
    "lr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K=20 fold cross validation score: 0.9066391498713132\n"
     ]
    }
   ],
   "source": [
    "# get k=20-fold CV score\n",
    "cross_val_scores = cross_val_score(lr, X_train, y_train, cv=20)\n",
    "cross_validation_score = cross_val_scores.mean()\n",
    "print(\"K=20 fold cross validation score: {}\".format(cross_validation_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BoW Approach\n",
    "\n",
    "This next approach will use a Bag-Of-Words approach to model sentiment. We'll perform a similar proces as with TF-IDF, but will change a few things. Specifically regarding data-preparation..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "# define a new bag of words approach that should get us some additional information\n",
    "# we want to look at number of words in sentence, how many times puncutation is used, how many nouns, verbs, adj, etc. length of previous sentence vs. length of next sentence\n",
    "def bow_feature_generator(sentences, common_words, verbose=False):\n",
    "    # we want to go through each sentence and count the number of occurances of verbs, nouns, adj, etc.\n",
    "    # we also want to count how many words are in each text\n",
    "    rows = []\n",
    "    for index, row in enumerate(sentences.itertuples()):\n",
    "        \n",
    "        sentence = row.text_sentence\n",
    "        source = row.CLASS_LABEL\n",
    "        \n",
    "        info_row = collections.defaultdict(int)\n",
    "        \n",
    "        for token in sentence:\n",
    "            part_of_speech = token.pos_\n",
    "            \n",
    "            if part_of_speech == \"VERB\":\n",
    "                # if it is a verb, add 1 for the sentence\n",
    "                info_row[\"n_verbs\"] += 1\n",
    "            elif part_of_speech == \"NOUN\":\n",
    "                # if it is a noun, add 1 for the noun to the sentence\n",
    "                info_row[\"n_nouns\"] += 1\n",
    "            \n",
    "            elif part_of_speech == \"ADJ\":\n",
    "                # if it is an adjective, add 1 for the adjective count for this sentence\n",
    "                info_row[\"n_adjectives\"] += 1\n",
    "            \n",
    "            info_row[\"n_words\"] += 1\n",
    "            \n",
    "            \n",
    "            if not token.is_punct and not token.is_stop and token.lemma_ in common_words:\n",
    "                info_row[token.lemma_] += 1\n",
    "        \n",
    "        if verbose:\n",
    "            if index % 10 == 0:\n",
    "                print(\"Operating on row: {}\".format(index))\n",
    "        \n",
    "        info_row = dict(info_row)\n",
    "        info_row[\"text_sentence\"] = sentence\n",
    "        info_row[\"CLASS_LABEL\"] = source\n",
    "        rows.append(info_row)\n",
    "    \n",
    "    \n",
    "    df = pd.DataFrame(data=rows, columns=[\"text_sentence\", \"n_verbs\", \"n_nouns\", \"n_adjectives\", \"n_words\"] + list(common_words) + [\"CLASS_LABEL\"])\n",
    "    \n",
    "    df = df.fillna(0)\n",
    "    \n",
    "    return df\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to create a list of the 2000 most common words.\n",
    "def bag_of_words(text):\n",
    "    \n",
    "    # Filter out punctuation and stop words.\n",
    "    allwords = [token.lemma_\n",
    "                for token in text\n",
    "                if not token.is_punct\n",
    "                and not token.is_stop]\n",
    "    \n",
    "    # Return the most common words.\n",
    "    return [item[0] for item in collections.Counter(allwords).most_common(2000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_sentence</th>\n",
       "      <th>CLASS_LABEL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(Easy, to, use, ,, economical, !, \\n)</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(Digital, is, where, it, ', s, at, ..., down, ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(Good, image, quality, ,, 3x, optical, zoom, ,...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(Cust, SVS, 2nd, 2, none, !, \\n)</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(intuitive, ,, user, friendly, \\n, Simple, ,, ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       text_sentence CLASS_LABEL\n",
       "0              (Easy, to, use, ,, economical, !, \\n)    positive\n",
       "1  (Digital, is, where, it, ', s, at, ..., down, ...    positive\n",
       "2  (Good, image, quality, ,, 3x, optical, zoom, ,...    positive\n",
       "3                   (Cust, SVS, 2nd, 2, none, !, \\n)    positive\n",
       "4  (intuitive, ,, user, friendly, \\n, Simple, ,, ...    positive"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert the sentences into one big corpus\n",
    "pros_raw = nlp(\"\\n\".join(pros_doc))\n",
    "cons_raw = nlp(\"\\n\".join(cons_doc))\n",
    "\n",
    "pros_sentences = [[sentence, \"positive\"] for sentence in pros_raw.sents]\n",
    "cons_sentences = [[sentence, \"negative\"] for sentence in cons_raw.sents]\n",
    "\n",
    "sentence_df = pd.DataFrame(pros_sentences + cons_sentences)\n",
    "sentence_df[\"text_sentence\"] = sentence_df[0]\n",
    "sentence_df[\"CLASS_LABEL\"] = sentence_df[1]\n",
    "sentence_df = sentence_df[[\"text_sentence\", \"CLASS_LABEL\"]]\n",
    "sentence_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "pros_common_words = bag_of_words(pros_raw)\n",
    "cons_common_words = bag_of_words(cons_raw)\n",
    "common_words = set(pros_common_words + cons_common_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_features = bow_feature_generator(sentence_df, common_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = bow_features.drop(columns=[\"text_sentence\", \"CLASS_LABEL\"])\n",
    "target = bow_features[\"CLASS_LABEL\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LogisticRegression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ryan/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for LogisticRegression...\n",
      "---------------------\n",
      "Best Score: 0.8942376619795974\n",
      "Train Score: 0.9233526330300524\n",
      "Test Score: 0.8961790814357391\n",
      "Best Params: {'C': 1.0}\n",
      "\n",
      "Training BernoulliNB\n",
      "Results for BernoulliNB...\n",
      "---------------------\n",
      "Best Score: 0.8797353184449959\n",
      "Train Score: 0.8877309070857458\n",
      "Test Score: 0.8800977743470989\n",
      "Best Params: {'alpha': 0.1}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# train our models\n",
    "find_best_model(tf_idf_models, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rerun with the best model and cv at 20 folds\n",
    "lr = LogisticRegression(solver=\"liblinear\", C=1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='liblinear',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K=20 fold cross val score: 0.8942415545295272\n"
     ]
    }
   ],
   "source": [
    "cross_validation_scores = cross_val_score(lr, X_train, y_train, cv=20)\n",
    "mean_cross_val_score = cross_validation_scores.mean()\n",
    "print(\"K=20 fold cross val score: {}\".format(mean_cross_val_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BoW wins (but not why you might think)\n",
    "\n",
    "While Tf-IDF had the higher cross val score, it didn't win by much. The reason why Tf-IDF loses here is not because of the score, but because of the real-world implementation. To compute the tf-idf matrix, it's required that we know the counts of words and number of documents across the entire corpus. Which means that if we wanted to predict a sentence as positive or negative, we'd need to compute the td-idf score for each sentence token, which doesn't really make sense. BoW can be used even if we don't have info around the other sentences.\n",
    "\n",
    "And that's why BoW wins, in the real world."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
