{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Classification: Malaria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Reshape, Dense, Conv2D, MaxPooling2D, GlobalAveragePooling2D, Flatten, Activation, Dropout\n",
    "from keras.optimizers import adadelta\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Import / Preparation\n",
    "\n",
    "Here we're dealing with quite a few images. In order to generalize the features in the images, we will zoom, scale and rotate each to add some variance in the input data. We're dealing with **quite** a bit of image data. The amount of data is pretty crazy, which means these networks should take a while to train.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        validation_split=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 27558 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = datagen.flow_from_directory(\n",
    "        'data/malaria-images',\n",
    "        target_size=(110, 110),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5510 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_generator = datagen.flow_from_directory(\n",
    "    'data/malaria-images', # same directory as training data\n",
    "    target_size=(110, 110),\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    "    subset='validation') # set as validation data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling\n",
    "\n",
    "The next few cells will demonstrate the use of a Convolutional Neural Network to classify these images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network from the groud up\n",
    "\n",
    "This model will be generated from scratch. This structure stems from some previous research into CNNs I did a few years ago."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3,3), padding='same', input_shape=(110, 110, 3)))\n",
    "# add an activation layer with ReLU\n",
    "model.add(Activation('relu'))\n",
    "# add Dnother convolutional layer\n",
    "model.add(Conv2D(32, (3,3)))\n",
    "# add another activation layer now\n",
    "model.add(Activation('relu'))\n",
    "# perform maxPooling\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "# finally add the dropout layer\n",
    "# add the dropout layer now, and drop out 25%\n",
    "model.add(Dropout(0.25))\n",
    "# same as before just increase kernal size by 2\n",
    "model.add(Conv2D(64, (3,3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "## our final layer bunch\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(train_generator.num_classes))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 110, 110, 32)      896       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 110, 110, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 108, 108, 32)      9248      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 108, 108, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 54, 54, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 54, 54, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 54, 54, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 54, 54, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 52, 52, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 52, 52, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 26, 26, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 26, 26, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 43264)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               22151680  \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 2)                 1026      \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 22,218,274\n",
      "Trainable params: 22,218,274\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile, fit and evaluate\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=adadelta(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "200/200 [==============================] - 344s 2s/step - loss: 0.6986 - acc: 0.5713 - val_loss: 0.6257 - val_acc: 0.6104\n",
      "Epoch 2/10\n",
      "200/200 [==============================] - 346s 2s/step - loss: 0.4570 - acc: 0.8262 - val_loss: 0.2698 - val_acc: 0.9219\n",
      "Epoch 3/10\n",
      "200/200 [==============================] - 383s 2s/step - loss: 0.2943 - acc: 0.9134 - val_loss: 0.4069 - val_acc: 0.9325\n",
      "Epoch 4/10\n",
      "200/200 [==============================] - 357s 2s/step - loss: 0.2567 - acc: 0.9217 - val_loss: 0.2207 - val_acc: 0.9330\n",
      "Epoch 5/10\n",
      "200/200 [==============================] - 369s 2s/step - loss: 0.2154 - acc: 0.9331 - val_loss: 0.1733 - val_acc: 0.9430\n",
      "Epoch 6/10\n",
      "200/200 [==============================] - 345s 2s/step - loss: 0.1708 - acc: 0.9497 - val_loss: 0.1857 - val_acc: 0.9410\n",
      "Epoch 7/10\n",
      "200/200 [==============================] - 374s 2s/step - loss: 0.1824 - acc: 0.9469 - val_loss: 0.1771 - val_acc: 0.9389\n",
      "Epoch 8/10\n",
      "200/200 [==============================] - 363s 2s/step - loss: 0.1781 - acc: 0.9461 - val_loss: 0.2817 - val_acc: 0.8954\n",
      "Epoch 9/10\n",
      "200/200 [==============================] - 396s 2s/step - loss: 0.1770 - acc: 0.9442 - val_loss: 0.1710 - val_acc: 0.9361\n",
      "Epoch 10/10\n",
      "200/200 [==============================] - 380s 2s/step - loss: 0.1688 - acc: 0.9480 - val_loss: 0.1673 - val_acc: 0.9454\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12ba8f978>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model on the batches generated by datagen.flow().\n",
    "model.fit_generator(train_generator, epochs=10, steps_per_epoch=200, validation_steps=200, validation_data=validation_generator, use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer Learning: VGG19\n",
    "\n",
    "This next model will use VGG but replace and re-train the last convolutional layer to generalize on our specific dataset. The reasoning behind this is that most of the \"grunt\" work has been done by the VGG model, and we're just focusing it on our domain specific content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 27558 images belonging to 2 classes.\n",
      "Found 5510 images belonging to 2 classes.\n",
      "Training Model using VGG19 with Imagenet weights...\n",
      "Epoch 1/10\n",
      "200/200 [==============================] - 3564s 18s/step - loss: 0.7511 - acc: 0.5059 - val_loss: 0.6932 - val_acc: 0.4956\n",
      "Epoch 2/10\n",
      "200/200 [==============================] - 3526s 18s/step - loss: 0.6934 - acc: 0.4909 - val_loss: 0.6932 - val_acc: 0.4965\n",
      "Epoch 3/10\n",
      "200/200 [==============================] - 3578s 18s/step - loss: 0.6930 - acc: 0.5134 - val_loss: 0.6935 - val_acc: 0.4978\n",
      "Epoch 4/10\n",
      "200/200 [==============================] - 3604s 18s/step - loss: 0.6934 - acc: 0.4927 - val_loss: 0.6933 - val_acc: 0.4961\n",
      "Epoch 5/10\n",
      "200/200 [==============================] - 3594s 18s/step - loss: 0.6932 - acc: 0.4980 - val_loss: 0.6933 - val_acc: 0.4989\n",
      "Epoch 6/10\n",
      "200/200 [==============================] - 3603s 18s/step - loss: 0.6933 - acc: 0.4986 - val_loss: 0.6931 - val_acc: 0.5009\n",
      "Epoch 7/10\n",
      "200/200 [==============================] - 3586s 18s/step - loss: 0.6932 - acc: 0.5016 - val_loss: 0.6932 - val_acc: 0.4961\n",
      "Epoch 8/10\n",
      "200/200 [==============================] - 3591s 18s/step - loss: 0.6933 - acc: 0.4964 - val_loss: 0.6931 - val_acc: 0.4994\n",
      "Epoch 9/10\n",
      "200/200 [==============================] - 3577s 18s/step - loss: 0.6932 - acc: 0.4943 - val_loss: 0.6932 - val_acc: 0.4947\n",
      "Epoch 10/10\n",
      "200/200 [==============================] - 3589s 18s/step - loss: 0.6931 - acc: 0.5080 - val_loss: 0.6932 - val_acc: 0.5025\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xb79e5f828>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import applications\n",
    "\n",
    "# re-define the generator to comply with VGG19 specs\n",
    "image_width, image_height = 256, 256\n",
    "data_generator = ImageDataGenerator(\n",
    "    preprocessing_function=applications.vgg19.preprocess_input,\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "train_generator = data_generator.flow_from_directory(\n",
    "    'data/malaria-images',\n",
    "    target_size=(image_width, image_height),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "validation_generator = data_generator.flow_from_directory(\n",
    "    'data/malaria-images',\n",
    "    target_size=(image_width, image_height),\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    "    subset=\"validation\" # set as validation data\n",
    ")\n",
    "\n",
    "\n",
    "model = applications.vgg19.VGG19(weights=\"imagenet\", include_top=False, input_shape=(image_width, image_height, 3))\n",
    "print(\"Training Model using VGG19 with Imagenet weights...\")\n",
    "\n",
    "# add our final layers to the network\n",
    "x = model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation=\"relu\")(x)\n",
    "\n",
    "predictions = Dense(train_generator.num_classes, activation=\"softmax\")(x) # a new softmax layer to provide the downsampling needeed\n",
    "# to predict which image type it is\n",
    "\n",
    "model = Model(inputs=model.input, outputs=predictions)\n",
    "\n",
    "\n",
    "# freeze all layers from being trainable except for our custom ones :)\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "# compile the model\n",
    "model.compile(optimizer=\"rmsprop\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# allow the last layers to be trainable (these are our layers)\n",
    "for layer in model.layers[17:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "# re-compile\n",
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# enable early stopping (so we don't keep trying to converge when we can't seem to anymore)\n",
    "early = EarlyStopping(monitor=\"val_acc\", min_delta=0, patience=10, verbose=1, mode=\"auto\")\n",
    "\n",
    "\n",
    "# finally fit the model and deliver the val scores\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    epochs=10,\n",
    "    steps_per_epoch=200,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=200,\n",
    "    class_weight=\"auto\",\n",
    "    use_multiprocessing=True,\n",
    "    callbacks=[early]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Another Model from Scratch\n",
    "\n",
    "Not only did the transfer learning in our case have a horrid accuracy score, it also took upwards of 10 hours. That is unacceptable. I need to model to be done fairly quickly. So, for that reason, I'll keep building my own for the next 3 cells. Making incremental changes to structure, etc.\n",
    "\n",
    "I want to try a very very small network to see if the \"deepness\" of the network has something to do with it. I'll use MaxPooling and Convolutional Layers, but won't use a Dropout layer in this one. (Hopefully I can see the effects of overfitting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 27558 images belonging to 2 classes.\n",
      "Found 5510 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# MARK: - Instantiate the image generators\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        validation_split=0.2\n",
    ")\n",
    "\n",
    "train_generator = datagen.flow_from_directory(\n",
    "        'data/malaria-images',\n",
    "        target_size=(110, 110),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')\n",
    "\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "    'data/malaria-images', # same directory as training data\n",
    "    target_size=(110, 110),\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    "    subset='validation') # set as validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3,3), padding='same', input_shape=(110, 110, 3)))\n",
    "# add an activation layer with ReLU\n",
    "model.add(Activation('relu'))\n",
    "# add Dnother convolutional layer\n",
    "model.add(Conv2D(32, (3,3)))\n",
    "# add another activation layer now\n",
    "model.add(Activation('relu'))\n",
    "# perform maxPooling\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "# # finally add the dropout layer\n",
    "# # add the dropout layer now, and drop out 25%\n",
    "# model.add(Dropout(0.25))\n",
    "# # same as before just increase kernal size by 2\n",
    "# model.add(Conv2D(64, (3,3), padding='same'))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Conv2D(64, (3,3)))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "# model.add(Dropout(0.25))\n",
    "# ## our final layer bunch\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(train_generator.num_classes))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 110, 110, 32)      896       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 110, 110, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 108, 108, 32)      9248      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 108, 108, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 54, 54, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 93312)             0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 512)               47776256  \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 2)                 1026      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 47,787,426\n",
      "Trainable params: 47,787,426\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile, fit and evaluate\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=adadelta(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "200/200 [==============================] - 339s 2s/step - loss: 0.7706 - acc: 0.5533 - val_loss: 0.6660 - val_acc: 0.5922\n",
      "Epoch 2/10\n",
      "200/200 [==============================] - 307s 2s/step - loss: 0.6316 - acc: 0.6498 - val_loss: 0.6534 - val_acc: 0.6197\n",
      "Epoch 3/10\n",
      "200/200 [==============================] - 323s 2s/step - loss: 0.3848 - acc: 0.8575 - val_loss: 0.2611 - val_acc: 0.9176\n",
      "Epoch 4/10\n",
      "200/200 [==============================] - 296s 1s/step - loss: 0.2535 - acc: 0.9172 - val_loss: 0.3236 - val_acc: 0.9264\n",
      "Epoch 5/10\n",
      "200/200 [==============================] - 407s 2s/step - loss: 0.2324 - acc: 0.9214 - val_loss: 0.2111 - val_acc: 0.9264\n",
      "Epoch 6/10\n",
      "200/200 [==============================] - 269s 1s/step - loss: 0.2165 - acc: 0.9294 - val_loss: 0.2215 - val_acc: 0.9247\n",
      "Epoch 7/10\n",
      "200/200 [==============================] - 275s 1s/step - loss: 0.2110 - acc: 0.9356 - val_loss: 0.2120 - val_acc: 0.9390\n",
      "Epoch 8/10\n",
      "200/200 [==============================] - 276s 1s/step - loss: 0.2102 - acc: 0.9348 - val_loss: 0.2031 - val_acc: 0.9322\n",
      "Epoch 9/10\n",
      "200/200 [==============================] - 284s 1s/step - loss: 0.2132 - acc: 0.9355 - val_loss: 0.1946 - val_acc: 0.9354\n",
      "Epoch 10/10\n",
      "200/200 [==============================] - 285s 1s/step - loss: 0.2030 - acc: 0.9384 - val_loss: 0.1877 - val_acc: 0.9398\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xb2ac29ac8>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model on the batches generated by datagen.flow()\n",
    "model.fit_generator(train_generator, epochs=10, steps_per_epoch=200, validation_steps=200, validation_data=validation_generator, use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method yielded a slightly lower validation accuracy than the first model. This does show that we don't quite need as many layers as at first sight. We also don't have any Dropout layers which is also very interesting. My guess is that since our domain of possible images is so small, the network would overfit to any other type of image, but not the one's we're feeding it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network without a CNN\n",
    "\n",
    "This next network will be a neural network with no convolutions. This will most definitely yield poorer results, just based on the current literature, but should be interesting nontheless."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Reshape((110, 110, 3), input_shape=(110, 110, 3)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dense(512))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dense(train_generator.num_classes))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape_1 (Reshape)          (None, 110, 110, 3)       0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 36300)             0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 1024)              37172224  \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 2)                 1026      \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 37,698,050\n",
      "Trainable params: 37,698,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "200/200 [==============================] - 126s 629ms/step - loss: 8.1834 - acc: 0.4906 - val_loss: 8.1299 - val_acc: 0.4956\n",
      "Epoch 2/10\n",
      "200/200 [==============================] - 128s 641ms/step - loss: 8.0062 - acc: 0.5033 - val_loss: 8.0034 - val_acc: 0.5035\n",
      "Epoch 3/10\n",
      "200/200 [==============================] - 133s 663ms/step - loss: 7.8047 - acc: 0.5158 - val_loss: 8.0944 - val_acc: 0.4978\n",
      "Epoch 4/10\n",
      "200/200 [==============================] - 130s 648ms/step - loss: 8.1976 - acc: 0.4914 - val_loss: 7.9958 - val_acc: 0.5039\n",
      "Epoch 5/10\n",
      "200/200 [==============================] - 131s 653ms/step - loss: 7.9994 - acc: 0.5037 - val_loss: 8.0767 - val_acc: 0.4989\n",
      "Epoch 6/10\n",
      "200/200 [==============================] - 138s 692ms/step - loss: 8.0742 - acc: 0.4991 - val_loss: 8.0742 - val_acc: 0.4991\n",
      "Epoch 7/10\n",
      "200/200 [==============================] - 122s 609ms/step - loss: 8.0716 - acc: 0.4992 - val_loss: 7.9956 - val_acc: 0.5039\n",
      "Epoch 8/10\n",
      "200/200 [==============================] - 118s 589ms/step - loss: 8.0767 - acc: 0.4989 - val_loss: 8.0692 - val_acc: 0.4994\n",
      "Epoch 9/10\n",
      "200/200 [==============================] - 124s 618ms/step - loss: 8.0170 - acc: 0.5026 - val_loss: 8.1450 - val_acc: 0.4947\n",
      "Epoch 10/10\n",
      "200/200 [==============================] - 125s 626ms/step - loss: 7.9306 - acc: 0.5080 - val_loss: 8.0186 - val_acc: 0.5025\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xb2cc3c0b8>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(train_generator, epochs=10, steps_per_epoch=200, validation_steps=200, validation_data=validation_generator, use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the accuracy of this model is attrocious. It's basically as if we flipped a coin. Let's try some additions to this non-CNN image classifier network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pooling without Convolution\n",
    "\n",
    "Just as a shot in the dark, let's add some MaxPooling to our layers, but still not use a Convolutional Layer at all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Reshape((110, 110, 3), input_shape=(110, 110, 3)))\n",
    "model.add(MaxPooling2D(pool_size=(3,3)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dense(512))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dense(train_generator.num_classes))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape_2 (Reshape)          (None, 110, 110, 3)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 36, 36, 3)         0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 3888)              0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 1024)              3982336   \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 2)                 1026      \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 4,508,162\n",
      "Trainable params: 4,508,162\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "200/200 [==============================] - 80s 398ms/step - loss: 8.2253 - acc: 0.4897 - val_loss: 8.1299 - val_acc: 0.4956\n",
      "Epoch 2/10\n",
      "200/200 [==============================] - 69s 345ms/step - loss: 7.9986 - acc: 0.5038 - val_loss: 8.0034 - val_acc: 0.5035\n",
      "Epoch 3/10\n",
      "200/200 [==============================] - 68s 342ms/step - loss: 7.8198 - acc: 0.5148 - val_loss: 8.0944 - val_acc: 0.4978\n",
      "Epoch 4/10\n",
      "200/200 [==============================] - 70s 348ms/step - loss: 8.1925 - acc: 0.4917 - val_loss: 7.9958 - val_acc: 0.5039\n",
      "Epoch 5/10\n",
      "200/200 [==============================] - 55s 275ms/step - loss: 7.9666 - acc: 0.5057 - val_loss: 8.0767 - val_acc: 0.4989\n",
      "Epoch 6/10\n",
      "200/200 [==============================] - 56s 278ms/step - loss: 8.0868 - acc: 0.4983 - val_loss: 8.0742 - val_acc: 0.4991\n",
      "Epoch 7/10\n",
      "200/200 [==============================] - 53s 267ms/step - loss: 8.0943 - acc: 0.4978 - val_loss: 7.9956 - val_acc: 0.5039\n",
      "Epoch 8/10\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 8.0742 - acc: 0.4991 - val_loss: 8.0692 - val_acc: 0.4994\n",
      "Epoch 9/10\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 7.9844 - acc: 0.5046 - val_loss: 8.1450 - val_acc: 0.4947\n",
      "Epoch 10/10\n",
      "200/200 [==============================] - 53s 263ms/step - loss: 7.9306 - acc: 0.5080 - val_loss: 8.0186 - val_acc: 0.5025\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xb2b93d1d0>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(train_generator, epochs=10, steps_per_epoch=200, validation_steps=200, validation_data=validation_generator, use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Seems like the best performing model was the first one we had, with a validation accuracy score of 0.94. The only other good model was a derivation of the first. The transfer learning was poor (not generalized enough to our domain) and I had **no hope** for the non-convolution networks. What is interesting is that even when we remove most of our first network (Pooling, Dropout, multiple convolutions) we still get basically the same validation accuracy score of around 0.93. My guess is that the first convolution find the edges of the malaria, no further steps required. We could output the result of the convolution, but I don't want to fiddle around with that. Interesting nonetheless."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
